<?xml version="1.0" encoding="UTF-8"?>
<governance:Policy xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:governance="https://datainmotion.com/mac/governance/1.0.0" xsi:schemaLocation="https://datainmotion.com/mac/governance/1.0.0 governance.ecore" policyId="eu-ai-act.default.en" type="EU_AI_ACT" name="EU AI Act Requirements" description="A comprehensive set of policy requirements based on the key articles and obligations of the European Union's Artificial Intelligence Act.">
  <requirementGroups name="Title II - Prohibited Artificial Intelligence Practices" description="Requirements related to AI practices that are considered to pose an unacceptable risk and are therefore prohibited.">
    <requirements requirementId="eu-ai-act.art5.1a" name="Art. 5(1)(a) Prohibition of subliminal techniques" description="The placing on the market, putting into service or use of an AI system that deploys subliminal techniques beyond a person’s consciousness in order to materially distort a person’s behaviour in a manner that causes or is likely to cause that person or another person physical or psychological harm is prohibited." documentationLink="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206" modality="MUST_NOT"/>
    <requirements requirementId="eu-ai-act.art5.1b" name="Art. 5(1)(b) Prohibition of exploitation of vulnerabilities" description="The placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of a specific group of persons due to their age, physical or mental disability, in order to materially distort the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm is prohibited." documentationLink="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206" modality="MUST_NOT"/>
    <requirements requirementId="eu-ai-act.art5.1c" name="Art. 5(1)(c) Prohibition of social scoring" description="The placing on the market, putting into service or use of AI systems by public authorities or on their behalf for the evaluation or classification of the trustworthiness of natural persons over a certain period of time based on their social behaviour or known or predicted personal or personality characteristics (social scoring) is prohibited if it leads to detrimental or unfavourable treatment." documentationLink="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206" modality="MUST_NOT"/>
    <requirements requirementId="eu-ai-act.art5.1d" name="Art. 5(1)(d) Prohibition of real-time remote biometric identification" description="The use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement is prohibited, unless subject to strict exceptions." documentationLink="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206" modality="MUST_NOT"/>
  </requirementGroups>
  <requirementGroups name="Title III, Chapter 2 - Requirements for High-Risk AI Systems" description="Key obligations that high-risk AI systems must comply with before they can be placed on the market or put into service.">
    <requirements requirementId="eu-ai-act.art9" name="Art. 9 Risk management system" description="A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems. It shall be a continuous iterative process planned and run throughout the entire lifecycle of a high-risk AI system." documentationLink="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206"/>
    <requirements requirementId="eu-ai-act.art10" name="Art. 10 Data and data governance" description="High-risk AI systems which make use of techniques involving the training of models with data shall be developed on the basis of training, validation and testing data sets that meet high quality criteria, including relevance, representativeness, and freedom from errors and bias." documentationLink="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206"/>
    <requirements requirementId="eu-ai-act.art11" name="Art. 11 Technical documentation" description="Technical documentation of a high-risk AI system shall be drawn up before that system is placed on the market or put into service and shall be kept up-to date. The documentation shall demonstrate that the system complies with the requirements." documentationLink="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206"/>
    <requirements requirementId="eu-ai-act.art12" name="Art. 12 Record-keeping" description="High-risk AI systems shall be designed and developed with capabilities enabling the automatic recording of events (‘logs’) while the system is operating. These logging capabilities shall conform to recognised standards or common specifications." documentationLink="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206"/>
    <requirements requirementId="eu-ai-act.art13" name="Art. 13 Transparency and provision of information to users" description="High-risk AI systems shall be designed and developed in such a way to ensure that their operation is sufficiently transparent to enable users to interpret the system’s output and use it appropriately. Instructions for use shall be provided." documentationLink="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206"/>
    <requirements requirementId="eu-ai-act.art14" name="Art. 14 Human oversight" description="High-risk AI systems shall be designed and developed in such a way, including with appropriate human-machine interface tools, that they can be effectively overseen by natural persons during the period in which the AI system is in use." documentationLink="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206"/>
    <requirements requirementId="eu-ai-act.art15" name="Art. 15 Accuracy, robustness and cybersecurity" description="High-risk AI systems shall be designed and developed in such a way that they achieve an appropriate level of accuracy, robustness and cybersecurity, and perform consistently in those respects throughout their lifecycle." documentationLink="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206"/>
  </requirementGroups>
  <requirementGroups name="Title IV - Transparency Obligations for Certain AI Systems" description="Requirements for AI systems intended to interact with natural persons or generate content.">
    <requirements requirementId="eu-ai-act.art52.1" name="Art. 52(1) Transparency of AI systems interacting with humans" description="Providers shall ensure that AI systems intended to interact with natural persons are designed and developed in such a way that natural persons are informed that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use." documentationLink="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206"/>
    <requirements requirementId="eu-ai-act.art52.2" name="Art. 52(2) Transparency of emotion recognition and biometric categorization" description="Users of an emotion recognition system or a biometric categorisation system shall inform the natural persons exposed thereto of the operation of the system." documentationLink="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206"/>
    <requirements requirementId="eu-ai-act.art52.3" name="Art. 52(3) Transparency of deep fakes" description="Users of an AI system that generates or manipulates image, audio or video content that appreciably resembles existing persons, objects, places or other entities or events and would falsely appear to a person to be authentic or truthful (‘deep fake’), shall disclose that the content has been artificially generated or manipulated." documentationLink="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206"/>
  </requirementGroups>
</governance:Policy>
